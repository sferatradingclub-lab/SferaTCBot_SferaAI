# Анализ реализации памяти и контекста Sfera AI

Этот документ содержит детальный анализ текущей реализации системы памяти, истории и контекста в проекте Sfera AI.

## 1. Обзор архитектуры

В проекте используются два типа памяти:
1.  **Краткосрочная/Эпизодическая память (Short-Term/Episodic)**: Реализована через **Qdrant** (векторная база данных). Хранит историю чатов и сообщения.
2.  **Долгосрочная память/Состояние (Long-Term/State)**: Реализована через **TinyDB** (`ltm_client.py`). Хранит профиль пользователя, текущий шаг обучения, диагнозы и имя.

## 2. Текущая реализация (Data Flow)

### 2.1. Инициализация (Startup)
При запуске агента (`agent.py` -> `entrypoint`):

1.  **Идентификация**: Агент получает `user_id` из метаданных LiveKit или Telegram.
2.  **LTM (TinyDB)**: Загружается имя пользователя через `LTMClient`.
3.  **Загрузка истории (Qdrant)**:
    *   Вызывается `mem0.get_all(filters={"user_id": user_id})`.
    *   Этот метод возвращает **все** сохраненные сообщения пользователя, отсортированные от новых к старым.
    *   В `agent.py` берется срез `[:config.agent.max_memories_to_load]` (по умолчанию 100 последних сообщений).
    *   Эти сообщения преобразуются в JSON-строку `memory_str`.
4.  **Внедрение в контекст**:
    *   `memory_str` добавляется в **системный промпт** агента под заголовком `# 5. ПАМЯТЬ ПРЕДЫДУЩИХ СЕССИЙ`.
    *   **Важно**: История не добавляется как сообщения чата (`chat_ctx.messages`), а как статический текст в инструкции.

### 2.2. В процессе работы
*   Агент "помнит" только то, что попало в системный промпт при старте (последние 100 сообщений).
*   **Семантический поиск не используется**: Агент не ищет информацию в базе знаний или старой памяти динамически в ответ на вопросы пользователя. Он полагается только на загруженный статический контекст.

### 2.3. Завершение сессии (Shutdown)
При остановке агента срабатывает `shutdown_hook`:

1.  Извлекаются все сообщения из *текущей* сессии (`chat_ctx.messages`).
2.  Фильтрация:
    *   Удаляются "мысли" агента (reasoning blocks).
    *   Пытается исключить дубликаты проверкой `if memory_str and memory_str in content_str`. **Это место проблемное**: `memory_str` — это JSON-массив, а `content_str` — одна строка. Условие почти всегда ложно, поэтому сохраняется всё.
3.  Сохранение:
    *   Отфильтрованные сообщения отправляются в Qdrant через `mem0.add`.
    *   Qdrant генерирует эмбеддинги (векторы) для сообщений и сохраняет их.

## 3. Выявленные проблемы

На основе анализа кода выявлены следующие причины проблем с памятью:

### 3.1. Отсутствие "умного" поиска (RAG)
Агент загружает **последние 100 сообщений** тупым списком. Если пользователь спросит о чем-то, что было 101 сообщение назад, агент это не вспомнит, даже если это есть в базе.
*   **Как должно быть**: При вопросе пользователя агент должен делать *семантический поиск* (`mem0.search`) по всей истории, чтобы найти релевантные фрагменты, а не грузить всё подряд.

### 3.2. Переполнение контекста
Загрузка 100 сообщений в формате JSON в системный промпт занимает огромное количество токенов. Это может:
*   Сбивать модель с толку.
*   Уменьшать место для генерации ответа.
*   Увеличивать задержку (latency) и стоимость.

### 3.3. Проблемы с дубликацией
Логика проверки дубликатов при сохранении (`shutdown_hook`) некорректна.
*   Если пользователь перезапускает агента часто, одни и те же сообщения могут сохраняться в базу снова и снова, засоряя векторный индекс.

### 3.4. Формат подачи памяти
Память подается как JSON-строка в системном промпте. Это не самый эффективный способ для LLM воспринимать диалог. Лучше подавать это как историю сообщений или как краткое резюме (Summary).

## 4. Рекомендации по исправлению

1.  **Внедрить RAG для памяти**: Вместо загрузки `get_all()`, использовать поиск похожих воспоминаний при каждом запросе пользователя (или через инструмент).
2.  **Оптимизировать загрузку**: При старте загружать только краткое саммари (если есть) и последние 10-20 сообщений, а не 100.
3.  **Исправить сохранение**: Переписать логику дедупликации в `shutdown_hook`. Использовать хэши сообщений или проверку по ID, чтобы не сохранять то, что уже есть.
4.  **Разделить память**:
    *   **Short-term**: Последние N сообщений в контексте чата.
    *   **Long-term**: Векторная база для поиска фактов из прошлого.
